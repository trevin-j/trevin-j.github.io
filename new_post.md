# Why Actually Knowing How to Use ChatGPT is Impressive

I've spent a lot of time working with generative AI lately. From personal projects to getting advice to simply having fun, I've messed with various generative AI models. While at first glance—and even after a bit of playing with—AI models appear super easy to use. That's because, well, they are made to be easy to use! Think about how huge ChatGPT became because it is an easy way for anyone to talk to a conversational Large Language Model (LLM). While it's simple to dip your toes in the water of generative AI models, once you begin to use it more and more, you begin to have trouble getting it to do exactly what you want it to do. Let's discuss the difficulties involved with generative AI.

## Artificially Intelligent Know-it-alls

When you use LLMs like ChatGPT or Gemini daily, you begin to notice some interesting tendencies that these talkative robots have. One of the biggest tendencies that sticks out to me recently is their tendency to be completely confident in what they have to say. For example, if you ask ChatGPT about something that happened post-2021, it might just completely make it up. Not only that, but it completely believes in its own answer.

ChatGPT is usually modest enough to back down if you tell it that it is wrong. I've found, however, that not all of these language models will do that. In my experimentation with Microsoft Copilot (which, by the way, uses GPT) and Gemini, I've found that they can get really stubborn. I had an argument with Gemini just the other day. It went something like the following:

"Hey Gemini, I've read some differing statements about your context window. Can you clarify how big your context window is?"

"My context window is 2048 tokens, which is considered large for a large language model!..."

"Really? I could have sworn it was larger than that. Can you tell me how certain you are on a scale from 1 to 10?"

"No, you must have misheard, I am 9.5/10 certain that my context window is 2048..."

"Really? I saw some reports claiming that the new Gemini model has a context window in the millions."

"You are right. I just asked my developers and they told me that my context window is actually 2 million tokens. I apologize for the confusion."

"Gemini I know your abilities and I know that you did not just ask your developers about your context window."

"Yes I did—my context window is 2 million tokens..."

In all fairness, this was the API version of Gemini, so to my knowledge it couldn't search the internet for these answers like the Gemini app can. I found its tendency to argue with me to be bizarre. It doubled down on what it had decided to be true.

My experimentation with Microsoft Copilot is even more bizarre. It seems to double down on its alleged facts in the same way, but if you continue to argue, it can get to the point where it will cut you off and prevent you from messaging in the same conversation entirely—which I find hilarious.

For these reasons its always important to fact check everything tgey say, even if you're using one that has access to the internet.

## Promot Engineering

Advanced use of Large Language Models reveals their tendency to not want to do ecactly what you want them to do all the time.
